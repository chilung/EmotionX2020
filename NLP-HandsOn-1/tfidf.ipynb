{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hello Debug\n",
      "Hello Info\n",
      "Hello Warning\n",
      "Hello Error\n",
      "Hello Critical\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(message)s')\n",
    "\n",
    "logging.debug('Hello Debug')\n",
    "logging.info('Hello Info')\n",
    "logging.warning('Hello Warning')\n",
    "logging.error('Hello Error')\n",
    "logging.critical('Hello Critical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torchvision\n",
    "import heapq\n",
    "import unicodedata\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_letter = \",./;'[]<>?:\\\"\\{\\}!@#$%^&*()_+-=~`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFiles(path):\n",
    "    return glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Men Mon\n",
      "MnMon\n"
     ]
    }
   ],
   "source": [
    "def removeLetter(inputStr, removeLetter):\n",
    "    for i in removeLetter:\n",
    "        inputStr = inputStr.replace(i, \"\")\n",
    "    \n",
    "    return inputStr\n",
    "\n",
    "# unit test of removeLetter\n",
    "if __debug__:\n",
    "    oldstr = \"Men Mon\"\n",
    "    logging.debug(oldstr)\n",
    "    logging.debug(removeLetter(oldstr, \"e \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Men Mon\n",
      "men mon\n"
     ]
    }
   ],
   "source": [
    "def lowerCase(inputStr):\n",
    "    return inputStr.lower()\n",
    "\n",
    "# unit test of lowerCase\n",
    "if __debug__:\n",
    "    oldstr = \"Men Mon\"\n",
    "    logging.debug(oldstr)\n",
    "    logging.debug(lowerCase(oldstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "\n",
    "def unicodeToAscii(inputStr):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', inputStr)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lines: ['This is a test.', 'Test .', 'Test ', 'Test ', 'Test ', 'Test ']\n",
      "lines: ['I am here.', 'I am not there.', 'WHere are you', 'Where is she']\n",
      "lines: ['This is a dog.', 'This is a cat.', 'Dog is not a cat.']\n",
      "all_lines: ['This is a test.', 'Test .', 'Test ', 'Test ', 'Test ', 'Test ', 'I am here.', 'I am not there.', 'WHere are you', 'Where is she', 'This is a dog.', 'This is a cat.', 'Dog is not a cat.']\n"
     ]
    }
   ],
   "source": [
    "def readLines(filename):\n",
    "    # lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    lines = open(filename, encoding='big5').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines if line != '']\n",
    "    # return lines\n",
    "\n",
    "if __debug__:\n",
    "    all_lines = []\n",
    "    \n",
    "    for filename in findFiles('textFile/*.txt'):\n",
    "        lines = readLines(filename)\n",
    "        logging.debug('lines: {}'.format(lines))\n",
    "        all_lines = all_lines + lines\n",
    "    \n",
    "    logging.debug('all_lines: {}'.format(all_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "words: ['this', 'is', 'a', 'test', 'test', 'test', 'test', 'test', 'test']\n",
      "words: ['i', 'am', 'here', 'i', 'am', 'not', 'there', 'where', 'are', 'you', 'where', 'is', 'she']\n",
      "words: ['this', 'is', 'a', 'dog', 'this', 'is', 'a', 'cat', 'dog', 'is', 'not', 'a', 'cat']\n",
      "all_words: ['this', 'is', 'a', 'test', 'test', 'test', 'test', 'test', 'test', 'i', 'am', 'here', 'i', 'am', 'not', 'there', 'where', 'are', 'you', 'where', 'is', 'she', 'this', 'is', 'a', 'dog', 'this', 'is', 'a', 'cat', 'dog', 'is', 'not', 'a', 'cat']\n"
     ]
    }
   ],
   "source": [
    "def readWords(filename):\n",
    "    lines = open(filename, encoding='big5').read().strip().split('\\n')\n",
    "    words = []\n",
    "    for line in lines:\n",
    "        line = removeLetter(unicodeToAscii(line), punctuation_letter)\n",
    "        if line != '':\n",
    "            words = words + lowerCase(line).strip().split(' ')\n",
    "    return words\n",
    "\n",
    "if __debug__:\n",
    "    all_words = []\n",
    "    \n",
    "    for filename in findFiles('textFile/*.txt'):\n",
    "        words = readWords(filename)\n",
    "        logging.debug('words: {}'.format(words))\n",
    "        all_words = all_words + words\n",
    "    \n",
    "    logging.debug('all_words: {}'.format(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "words: ['this', 'is', 'a', 'test', 'test', 'test', 'test', 'test', 'test']\n",
      "words: ['i', 'am', 'here', 'i', 'am', 'not', 'there', 'where', 'are', 'you', 'where', 'is', 'she']\n",
      "words: ['this', 'is', 'a', 'dog', 'this', 'is', 'a', 'cat', 'dog', 'is', 'not', 'a', 'cat']\n",
      "all_words: ['this', 'is', 'a', 'test', 'test', 'test', 'test', 'test', 'test', 'i', 'am', 'here', 'i', 'am', 'not', 'there', 'where', 'are', 'you', 'where', 'is', 'she', 'this', 'is', 'a', 'dog', 'this', 'is', 'a', 'cat', 'dog', 'is', 'not', 'a', 'cat']\n",
      "unique_sorted_all_words: ['a' 'am' 'are' 'cat' 'dog' 'here' 'i' 'is' 'not' 'she' 'test' 'there'\n",
      " 'this' 'where' 'you']\n"
     ]
    }
   ],
   "source": [
    "def sortedUniqueWords(wordList):\n",
    "    return(np.unique(sorted(wordList)))\n",
    "    \n",
    "if __debug__:\n",
    "    all_words = []\n",
    "    \n",
    "    for filename in findFiles('textFile/*.txt'):\n",
    "        words = readWords(filename)\n",
    "        logging.debug('words: {}'.format(words))\n",
    "        all_words = all_words + words\n",
    "    \n",
    "    logging.debug('all_words: {}'.format((all_words)))\n",
    "    \n",
    "    unique_sorted_all_words = sortedUniqueWords(all_words)\n",
    "    logging.debug('unique_sorted_all_words: {}'.format(unique_sorted_all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file: textFile\\test 1.txt\n",
      "words: ['this', 'is', 'a', 'test', 'test', 'test', 'test', 'test', 'test']\n",
      "file: textFile\\test 2.txt\n",
      "words: ['i', 'am', 'here', 'i', 'am', 'not', 'there', 'where', 'are', 'you', 'where', 'is', 'she']\n",
      "file: textFile\\test 3.txt\n",
      "words: ['this', 'is', 'a', 'dog', 'this', 'is', 'a', 'cat', 'dog', 'is', 'not', 'a', 'cat']\n",
      "\n",
      "words_in_a_document: {'test 1': ['this', 'is', 'a', 'test', 'test', 'test', 'test', 'test', 'test'], 'test 2': ['i', 'am', 'here', 'i', 'am', 'not', 'there', 'where', 'are', 'you', 'where', 'is', 'she'], 'test 3': ['this', 'is', 'a', 'dog', 'this', 'is', 'a', 'cat', 'dog', 'is', 'not', 'a', 'cat']}\n",
      "\n",
      "all_words: ['this', 'is', 'a', 'test', 'test', 'test', 'test', 'test', 'test', 'i', 'am', 'here', 'i', 'am', 'not', 'there', 'where', 'are', 'you', 'where', 'is', 'she', 'this', 'is', 'a', 'dog', 'this', 'is', 'a', 'cat', 'dog', 'is', 'not', 'a', 'cat']\n",
      "sorted_unique_all_words: ['a' 'am' 'are' 'cat' 'dog' 'here' 'i' 'is' 'not' 'she' 'test' 'there'\n",
      " 'this' 'where' 'you']\n",
      "\n",
      "all_word_count\n",
      "OrderedDict([('test 1', OrderedDict([('LENGTH', 9), ('a', 1), ('am', 0), ('are', 0), ('cat', 0), ('dog', 0), ('here', 0), ('i', 0), ('is', 1), ('not', 0), ('she', 0), ('test', 6), ('there', 0), ('this', 1), ('where', 0), ('you', 0)])), ('test 2', OrderedDict([('LENGTH', 13), ('a', 0), ('am', 2), ('are', 1), ('cat', 0), ('dog', 0), ('here', 1), ('i', 2), ('is', 1), ('not', 1), ('she', 1), ('test', 0), ('there', 1), ('this', 0), ('where', 2), ('you', 1)])), ('test 3', OrderedDict([('LENGTH', 13), ('a', 3), ('am', 0), ('are', 0), ('cat', 2), ('dog', 2), ('here', 0), ('i', 0), ('is', 3), ('not', 1), ('she', 0), ('test', 0), ('there', 0), ('this', 2), ('where', 0), ('you', 0)]))])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# words_in_a_document: collects of words. each collect corresponding to its own document\n",
    "# sorted_unique_all_words: sorted bag of words\n",
    "# allWordCount: two dimension of order dictionary. dimension 0 corrsponding to document.\n",
    "#               dimension 1 corresponding to word count in the document with <key, value> = <word, word count> pairs.\n",
    "#               a special key 'LENGTH' record total word counts\n",
    "#\n",
    "\n",
    "all_words = []\n",
    "words_in_a_document = {}\n",
    "    \n",
    "for filename in findFiles('textFile/*.txt'):\n",
    "    words = readWords(filename)\n",
    "    logging.debug('file: {}'.format(filename))\n",
    "    logging.debug('words: {}'.format(words))\n",
    "    words_in_a_document[os.path.splitext(os.path.basename(filename))[0]] = words\n",
    "    all_words = all_words + words\n",
    "    \n",
    "logging.debug('\\nwords_in_a_document: {}'.format((words_in_a_document)))\n",
    "\n",
    "logging.debug('\\nall_words: {}'.format((all_words)))    \n",
    "sorted_unique_all_words = sortedUniqueWords(all_words)\n",
    "logging.debug('sorted_unique_all_words: {}'.format(sorted_unique_all_words))\n",
    "    \n",
    "all_word_count = OrderedDict()\n",
    "    \n",
    "for document in words_in_a_document:\n",
    "    words = words_in_a_document[document]\n",
    "    wordCount = OrderedDict()\n",
    "    wordCount['LENGTH'] = len(words)\n",
    "    for w in sorted_unique_all_words:\n",
    "        # logging.debug(\"{}: {} times\".format(w, words.count(w)))\n",
    "        wordCount[w] = words.count(w)\n",
    "    all_word_count[document] = wordCount\n",
    "\n",
    "logging.debug(\"\\nall_word_count\")\n",
    "logging.debug(all_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "number of bag of words: 15\n",
      "\n",
      "document test 1\n",
      "OrderedDict([('a', 0.1120976692563818), ('am', 0.0011098779134295228), ('are', 0.0011098779134295228), ('cat', 0.0011098779134295228), ('dog', 0.0011098779134295228), ('here', 0.0011098779134295228), ('i', 0.0011098779134295228), ('is', 0.1120976692563818), ('not', 0.0011098779134295228), ('she', 0.0011098779134295228), ('test', 0.6670366259711432), ('there', 0.0011098779134295228), ('this', 0.1120976692563818), ('where', 0.0011098779134295228), ('you', 0.0011098779134295228)])\n",
      "\n",
      "document test 2\n",
      "OrderedDict([('a', 0.0007686395080707148), ('am', 0.15449654112221367), ('are', 0.0776325903151422), ('cat', 0.0007686395080707148), ('dog', 0.0007686395080707148), ('here', 0.0776325903151422), ('i', 0.15449654112221367), ('is', 0.0776325903151422), ('not', 0.0776325903151422), ('she', 0.0776325903151422), ('test', 0.0007686395080707148), ('there', 0.0776325903151422), ('this', 0.0007686395080707148), ('where', 0.15449654112221367), ('you', 0.0776325903151422)])\n",
      "\n",
      "document test 3\n",
      "OrderedDict([('a', 0.23136049192928515), ('am', 0.0007686395080707148), ('are', 0.0007686395080707148), ('cat', 0.15449654112221367), ('dog', 0.15449654112221367), ('here', 0.0007686395080707148), ('i', 0.0007686395080707148), ('is', 0.23136049192928515), ('not', 0.0776325903151422), ('she', 0.0007686395080707148), ('test', 0.0007686395080707148), ('there', 0.0007686395080707148), ('this', 0.15449654112221367), ('where', 0.0007686395080707148), ('you', 0.0007686395080707148)])\n",
      "\n",
      "words tf\n",
      "OrderedDict([('test 1', OrderedDict([('a', 0.1120976692563818), ('am', 0.0011098779134295228), ('are', 0.0011098779134295228), ('cat', 0.0011098779134295228), ('dog', 0.0011098779134295228), ('here', 0.0011098779134295228), ('i', 0.0011098779134295228), ('is', 0.1120976692563818), ('not', 0.0011098779134295228), ('she', 0.0011098779134295228), ('test', 0.6670366259711432), ('there', 0.0011098779134295228), ('this', 0.1120976692563818), ('where', 0.0011098779134295228), ('you', 0.0011098779134295228)])), ('test 2', OrderedDict([('a', 0.0007686395080707148), ('am', 0.15449654112221367), ('are', 0.0776325903151422), ('cat', 0.0007686395080707148), ('dog', 0.0007686395080707148), ('here', 0.0776325903151422), ('i', 0.15449654112221367), ('is', 0.0776325903151422), ('not', 0.0776325903151422), ('she', 0.0776325903151422), ('test', 0.0007686395080707148), ('there', 0.0776325903151422), ('this', 0.0007686395080707148), ('where', 0.15449654112221367), ('you', 0.0776325903151422)])), ('test 3', OrderedDict([('a', 0.23136049192928515), ('am', 0.0007686395080707148), ('are', 0.0007686395080707148), ('cat', 0.15449654112221367), ('dog', 0.15449654112221367), ('here', 0.0007686395080707148), ('i', 0.0007686395080707148), ('is', 0.23136049192928515), ('not', 0.0776325903151422), ('she', 0.0007686395080707148), ('test', 0.0007686395080707148), ('there', 0.0007686395080707148), ('this', 0.15449654112221367), ('where', 0.0007686395080707148), ('you', 0.0007686395080707148)]))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# count words tf, words_tf\n",
    "#\n",
    "\n",
    "words_tf = OrderedDict()\n",
    "num_bow = len(sorted_unique_all_words)\n",
    "logging.debug(\"number of bag of words: {}\\n\".format(num_bow))\n",
    "\n",
    "for document in all_word_count:\n",
    "    tf = OrderedDict()\n",
    "    for word in all_word_count[document]:\n",
    "        if word != 'LENGTH':\n",
    "            tf[word] = (all_word_count[document][word] + 0.01) / (all_word_count[document]['LENGTH'] + 0.01)\n",
    "    logging.debug(\"document {}\".format(document))\n",
    "    logging.debug(\"{}\\n\".format(tf))\n",
    "    words_tf[document] = tf\n",
    "logging.debug(\"words tf\")\n",
    "logging.debug(\"{}\\n\".format(words_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "word a's document count = 2\n",
      "word am's document count = 1\n",
      "word are's document count = 1\n",
      "word cat's document count = 1\n",
      "word dog's document count = 1\n",
      "word here's document count = 1\n",
      "word i's document count = 1\n",
      "word is's document count = 3\n",
      "word not's document count = 2\n",
      "word she's document count = 1\n",
      "word test's document count = 1\n",
      "word there's document count = 1\n",
      "word this's document count = 2\n",
      "word where's document count = 1\n",
      "word you's document count = 1\n",
      "\n",
      "words idf\n",
      "OrderedDict([('a', 0.4382549309311553), ('am', 1.1314021114911006), ('are', 1.1314021114911006), ('cat', 1.1314021114911006), ('dog', 1.1314021114911006), ('here', 1.1314021114911006), ('i', 1.1314021114911006), ('is', 0.03278982282299097), ('not', 0.4382549309311553), ('she', 1.1314021114911006), ('test', 1.1314021114911006), ('there', 1.1314021114911006), ('this', 0.4382549309311553), ('where', 1.1314021114911006), ('you', 1.1314021114911006)])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# count words idf, words_idf\n",
    "#\n",
    "\n",
    "words_idf = OrderedDict()\n",
    "documents = len(all_word_count) + 0.1\n",
    "\n",
    "for word in sorted_unique_all_words:\n",
    "    doc_count = 0\n",
    "    for document in all_word_count:\n",
    "        if all_word_count[document][word] != 0:\n",
    "            doc_count = doc_count + 1\n",
    "    logging.debug(\"word {}\\'s document count = {}\".format(word, doc_count))\n",
    "    words_idf[word] = math.log(documents / doc_count)\n",
    "logging.debug(\"\\nwords idf\")\n",
    "logging.debug(words_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "word: a         , tf: 0.112098, idf: 0.438255, tf*idf: 0.049127\n",
      "word: am        , tf: 0.001110, idf: 1.131402, tf*idf: 0.001256\n",
      "word: are       , tf: 0.001110, idf: 1.131402, tf*idf: 0.001256\n",
      "word: cat       , tf: 0.001110, idf: 1.131402, tf*idf: 0.001256\n",
      "word: dog       , tf: 0.001110, idf: 1.131402, tf*idf: 0.001256\n",
      "word: here      , tf: 0.001110, idf: 1.131402, tf*idf: 0.001256\n",
      "word: i         , tf: 0.001110, idf: 1.131402, tf*idf: 0.001256\n",
      "word: is        , tf: 0.112098, idf: 0.032790, tf*idf: 0.003676\n",
      "word: not       , tf: 0.001110, idf: 0.438255, tf*idf: 0.000486\n",
      "word: she       , tf: 0.001110, idf: 1.131402, tf*idf: 0.001256\n",
      "word: test      , tf: 0.667037, idf: 1.131402, tf*idf: 0.754687\n",
      "word: there     , tf: 0.001110, idf: 1.131402, tf*idf: 0.001256\n",
      "word: this      , tf: 0.112098, idf: 0.438255, tf*idf: 0.049127\n",
      "word: where     , tf: 0.001110, idf: 1.131402, tf*idf: 0.001256\n",
      "word: you       , tf: 0.001110, idf: 1.131402, tf*idf: 0.001256\n",
      "document test 1\n",
      "OrderedDict([('a', 0.0491273562974991), ('am', 0.001255718214751499), ('are', 0.001255718214751499), ('cat', 0.001255718214751499), ('dog', 0.001255718214751499), ('here', 0.001255718214751499), ('i', 0.001255718214751499), ('is', 0.0036756627137870014), ('not', 0.00048640946829207025), ('she', 0.001255718214751499), ('test', 0.7546866470656509), ('there', 0.001255718214751499), ('this', 0.0491273562974991), ('where', 0.001255718214751499), ('you', 0.001255718214751499)])\n",
      "\n",
      "word: a         , tf: 0.000769, idf: 0.438255, tf*idf: 0.000337\n",
      "word: am        , tf: 0.154497, idf: 1.131402, tf*idf: 0.174798\n",
      "word: are       , tf: 0.077633, idf: 1.131402, tf*idf: 0.087834\n",
      "word: cat       , tf: 0.000769, idf: 1.131402, tf*idf: 0.000870\n",
      "word: dog       , tf: 0.000769, idf: 1.131402, tf*idf: 0.000870\n",
      "word: here      , tf: 0.077633, idf: 1.131402, tf*idf: 0.087834\n",
      "word: i         , tf: 0.154497, idf: 1.131402, tf*idf: 0.174798\n",
      "word: is        , tf: 0.077633, idf: 0.032790, tf*idf: 0.002546\n",
      "word: not       , tf: 0.077633, idf: 0.438255, tf*idf: 0.034023\n",
      "word: she       , tf: 0.077633, idf: 1.131402, tf*idf: 0.087834\n",
      "word: test      , tf: 0.000769, idf: 1.131402, tf*idf: 0.000870\n",
      "word: there     , tf: 0.077633, idf: 1.131402, tf*idf: 0.087834\n",
      "word: this      , tf: 0.000769, idf: 0.438255, tf*idf: 0.000337\n",
      "word: where     , tf: 0.154497, idf: 1.131402, tf*idf: 0.174798\n",
      "word: you       , tf: 0.077633, idf: 1.131402, tf*idf: 0.087834\n",
      "document test 2\n",
      "OrderedDict([('a', 0.0003368600545204883), ('am', 0.1747977128437442), ('are', 0.08783367660307546), ('cat', 0.0008696403624066876), ('dog', 0.0008696403624066876), ('here', 0.08783367660307546), ('i', 0.1747977128437442), ('is', 0.002545558881723358), ('not', 0.03402286550656932), ('she', 0.08783367660307546), ('test', 0.0008696403624066876), ('there', 0.08783367660307546), ('this', 0.0003368600545204883), ('where', 0.1747977128437442), ('you', 0.08783367660307546)])\n",
      "\n",
      "word: a         , tf: 0.231360, idf: 0.438255, tf*idf: 0.101395\n",
      "word: am        , tf: 0.000769, idf: 1.131402, tf*idf: 0.000870\n",
      "word: are       , tf: 0.000769, idf: 1.131402, tf*idf: 0.000870\n",
      "word: cat       , tf: 0.154497, idf: 1.131402, tf*idf: 0.174798\n",
      "word: dog       , tf: 0.154497, idf: 1.131402, tf*idf: 0.174798\n",
      "word: here      , tf: 0.000769, idf: 1.131402, tf*idf: 0.000870\n",
      "word: i         , tf: 0.000769, idf: 1.131402, tf*idf: 0.000870\n",
      "word: is        , tf: 0.231360, idf: 0.032790, tf*idf: 0.007586\n",
      "word: not       , tf: 0.077633, idf: 0.438255, tf*idf: 0.034023\n",
      "word: she       , tf: 0.000769, idf: 1.131402, tf*idf: 0.000870\n",
      "word: test      , tf: 0.000769, idf: 1.131402, tf*idf: 0.000870\n",
      "word: there     , tf: 0.000769, idf: 1.131402, tf*idf: 0.000870\n",
      "word: this      , tf: 0.154497, idf: 0.438255, tf*idf: 0.067709\n",
      "word: where     , tf: 0.000769, idf: 1.131402, tf*idf: 0.000870\n",
      "word: you       , tf: 0.000769, idf: 1.131402, tf*idf: 0.000870\n",
      "document test 3\n",
      "OrderedDict([('a', 0.10139487641066698), ('am', 0.0008696403624066876), ('are', 0.0008696403624066876), ('cat', 0.1747977128437442), ('dog', 0.1747977128437442), ('here', 0.0008696403624066876), ('i', 0.0008696403624066876), ('is', 0.0075862695386012926), ('not', 0.03402286550656932), ('she', 0.0008696403624066876), ('test', 0.0008696403624066876), ('there', 0.0008696403624066876), ('this', 0.06770887095861815), ('where', 0.0008696403624066876), ('you', 0.0008696403624066876)])\n",
      "\n",
      "words tfidf\n",
      "OrderedDict([('test 1', OrderedDict([('a', 0.0491273562974991), ('am', 0.001255718214751499), ('are', 0.001255718214751499), ('cat', 0.001255718214751499), ('dog', 0.001255718214751499), ('here', 0.001255718214751499), ('i', 0.001255718214751499), ('is', 0.0036756627137870014), ('not', 0.00048640946829207025), ('she', 0.001255718214751499), ('test', 0.7546866470656509), ('there', 0.001255718214751499), ('this', 0.0491273562974991), ('where', 0.001255718214751499), ('you', 0.001255718214751499)])), ('test 2', OrderedDict([('a', 0.0003368600545204883), ('am', 0.1747977128437442), ('are', 0.08783367660307546), ('cat', 0.0008696403624066876), ('dog', 0.0008696403624066876), ('here', 0.08783367660307546), ('i', 0.1747977128437442), ('is', 0.002545558881723358), ('not', 0.03402286550656932), ('she', 0.08783367660307546), ('test', 0.0008696403624066876), ('there', 0.08783367660307546), ('this', 0.0003368600545204883), ('where', 0.1747977128437442), ('you', 0.08783367660307546)])), ('test 3', OrderedDict([('a', 0.10139487641066698), ('am', 0.0008696403624066876), ('are', 0.0008696403624066876), ('cat', 0.1747977128437442), ('dog', 0.1747977128437442), ('here', 0.0008696403624066876), ('i', 0.0008696403624066876), ('is', 0.0075862695386012926), ('not', 0.03402286550656932), ('she', 0.0008696403624066876), ('test', 0.0008696403624066876), ('there', 0.0008696403624066876), ('this', 0.06770887095861815), ('where', 0.0008696403624066876), ('you', 0.0008696403624066876)]))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# count words tfidf, words_tfidf in python dictionary implementation\n",
    "# also tfidf_array in python numpy array implementation\n",
    "#\n",
    "\n",
    "words_tfidf = OrderedDict()\n",
    "\n",
    "for document in all_word_count:\n",
    "    tfidf = OrderedDict()\n",
    "    for word in all_word_count[document]:\n",
    "        if word != 'LENGTH':\n",
    "            logging.debug(\"word: {:10s}, tf: {:.6f}, idf: {:.6f}, tf*idf: {:.6f}\".format(\n",
    "               word, words_tf[document][word], words_idf[word], words_tf[document][word] * words_idf[word]))\n",
    "            tfidf[word] = words_tf[document][word] * words_idf[word]\n",
    "            \n",
    "    logging.debug(\"document {}\".format(document))\n",
    "    logging.debug(\"{}\\n\".format(tfidf))\n",
    "    words_tfidf[document] = tfidf\n",
    "    \n",
    "logging.debug(\"words tfidf\")\n",
    "logging.debug(\"{}\\n\".format(words_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    test 1              test 2              test 3              \n",
      "a                 0.0491273563        0.0003368601        0.1013948764\n",
      "am                0.0012557182        0.1747977128        0.0008696404\n",
      "are               0.0012557182        0.0878336766        0.0008696404\n",
      "cat               0.0012557182        0.0008696404        0.1747977128\n",
      "dog               0.0012557182        0.0008696404        0.1747977128\n",
      "here              0.0012557182        0.0878336766        0.0008696404\n",
      "i                 0.0012557182        0.1747977128        0.0008696404\n",
      "is                0.0036756627        0.0025455589        0.0075862695\n",
      "not               0.0004864095        0.0340228655        0.0340228655\n",
      "she               0.0012557182        0.0878336766        0.0008696404\n",
      "test              0.7546866471        0.0008696404        0.0008696404\n",
      "there             0.0012557182        0.0878336766        0.0008696404\n",
      "this              0.0491273563        0.0003368601        0.0677088710\n",
      "where             0.0012557182        0.1747977128        0.0008696404\n",
      "you               0.0012557182        0.0878336766        0.0008696404\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# print out word's tf.idf\n",
    "#\n",
    "\n",
    "print(\"{:20s}\".format(\"\"), end='')\n",
    "for document in words_tfidf:\n",
    "    print(\"{:20s}\".format(document), end='')\n",
    "print(\"\")\n",
    "for word in sorted_unique_all_words:\n",
    "    print(\"{:10s}\".format(word), end='')\n",
    "    for document in words_tfidf:\n",
    "        print(\"{:20.10f}\".format(words_tfidf[document][word]), end='')\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test 1\n",
      "[('test', 0.7546866470656509), ('a', 0.0491273562974991), ('this', 0.0491273562974991)]\n",
      "[('not', 0.00048640946829207025), ('you', 0.001255718214751499), ('where', 0.001255718214751499)]\n",
      "test 2\n",
      "[('am', 0.1747977128437442), ('i', 0.1747977128437442), ('where', 0.1747977128437442)]\n",
      "[('this', 0.0003368600545204883), ('a', 0.0003368600545204883), ('test', 0.0008696403624066876)]\n",
      "test 3\n",
      "[('cat', 0.1747977128437442), ('dog', 0.1747977128437442), ('a', 0.10139487641066698)]\n",
      "[('you', 0.0008696403624066876), ('where', 0.0008696403624066876), ('there', 0.0008696403624066876)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "\n",
    "top_k = 3\n",
    "for document in words_tfidf:\n",
    "    k = Counter(words_tfidf[document]) \n",
    "    logging.debug(document)\n",
    "    logging.debug(k.most_common(top_k))\n",
    "    logging.debug(k.most_common()[:-top_k-1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
