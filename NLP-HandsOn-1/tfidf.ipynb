{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hello Debug\n",
      "Hello Info\n",
      "Hello Warning\n",
      "Hello Error\n",
      "Hello Critical\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(message)s')\n",
    "\n",
    "logging.debug('Hello Debug')\n",
    "logging.info('Hello Info')\n",
    "logging.warning('Hello Warning')\n",
    "logging.error('Hello Error')\n",
    "logging.critical('Hello Critical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torchvision\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_letter = \",./;'[]<>?:\\\"\\{\\}!@#$%^&*()_+-=~`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFiles(path):\n",
    "    return glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Men Mon\n",
      "MnMon\n"
     ]
    }
   ],
   "source": [
    "def removeLetter(inputStr, removeLetter):\n",
    "    for i in removeLetter:\n",
    "        inputStr = inputStr.replace(i, \"\")\n",
    "    \n",
    "    return inputStr\n",
    "\n",
    "# unit test of removeLetter\n",
    "if __debug__:\n",
    "    oldstr = \"Men Mon\"\n",
    "    logging.debug(oldstr)\n",
    "    logging.debug(removeLetter(oldstr, \"e \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Men Mon\n",
      "men mon\n"
     ]
    }
   ],
   "source": [
    "def lowerCase(inputStr):\n",
    "    return inputStr.lower()\n",
    "\n",
    "# unit test of lowerCase\n",
    "if __debug__:\n",
    "    oldstr = \"Men Mon\"\n",
    "    logging.debug(oldstr)\n",
    "    logging.debug(lowerCase(oldstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(inputStr):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', inputStr)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lines: ['his is a test.', 'Test .', 'Test ?', 'Test /', 'Test \"', 'Test :']\n",
      "lines: ['I am here.', 'I am not there.', 'WHere are you?', 'Where is she?']\n",
      "lines: ['This is a dog.', 'This is a cat.', 'Dog is not a cat.']\n",
      "all_lines: ['his is a test.', 'Test .', 'Test ?', 'Test /', 'Test \"', 'Test :', 'I am here.', 'I am not there.', 'WHere are you?', 'Where is she?', 'This is a dog.', 'This is a cat.', 'Dog is not a cat.']\n"
     ]
    }
   ],
   "source": [
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [line for line in lines if line != '']\n",
    "    # return lines\n",
    "\n",
    "if __debug__:\n",
    "    all_lines = []\n",
    "    \n",
    "    for filename in findFiles('textFile/*.txt'):\n",
    "        lines = readLines(filename)\n",
    "        logging.debug('lines: {}'.format(lines))\n",
    "        all_lines = all_lines + lines\n",
    "    \n",
    "    logging.debug('all_lines: {}'.format(all_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "words: ['his', 'is', 'a', 'test', 'test', 'test', 'test', 'test', 'test']\n",
      "words: ['i', 'am', 'here', 'i', 'am', 'not', 'there', 'where', 'are', 'you', 'where', 'is', 'she']\n",
      "words: ['this', 'is', 'a', 'dog', 'this', 'is', 'a', 'cat', 'dog', 'is', 'not', 'a', 'cat']\n",
      "all_words: ['his', 'is', 'a', 'test', 'test', 'test', 'test', 'test', 'test', 'i', 'am', 'here', 'i', 'am', 'not', 'there', 'where', 'are', 'you', 'where', 'is', 'she', 'this', 'is', 'a', 'dog', 'this', 'is', 'a', 'cat', 'dog', 'is', 'not', 'a', 'cat']\n"
     ]
    }
   ],
   "source": [
    "def readWords(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    words = []\n",
    "    for line in lines:\n",
    "        line = removeLetter(line, punctuation_letter)\n",
    "        if line != '':\n",
    "            words = words + lowerCase(line).strip().split(' ')\n",
    "    return words\n",
    "\n",
    "if __debug__:\n",
    "    all_words = []\n",
    "    \n",
    "    for filename in findFiles('textFile/*.txt'):\n",
    "        words = readWords(filename)\n",
    "        logging.debug('words: {}'.format(words))\n",
    "        all_words = all_words + words\n",
    "    \n",
    "    logging.debug('all_words: {}'.format(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "words: ['his', 'is', 'a', 'test', 'test', 'test', 'test', 'test', 'test']\n",
      "words: ['i', 'am', 'here', 'i', 'am', 'not', 'there', 'where', 'are', 'you', 'where', 'is', 'she']\n",
      "words: ['this', 'is', 'a', 'dog', 'this', 'is', 'a', 'cat', 'dog', 'is', 'not', 'a', 'cat']\n",
      "all_words: ['his', 'is', 'a', 'test', 'test', 'test', 'test', 'test', 'test', 'i', 'am', 'here', 'i', 'am', 'not', 'there', 'where', 'are', 'you', 'where', 'is', 'she', 'this', 'is', 'a', 'dog', 'this', 'is', 'a', 'cat', 'dog', 'is', 'not', 'a', 'cat']\n",
      "unique_sorted_all_words: ['a' 'am' 'are' 'cat' 'dog' 'here' 'his' 'i' 'is' 'not' 'she' 'test'\n",
      " 'there' 'this' 'where' 'you']\n"
     ]
    }
   ],
   "source": [
    "def sortedUniqueWords(wordList):\n",
    "    return(np.unique(sorted(wordList)))\n",
    "    \n",
    "if __debug__:\n",
    "    all_words = []\n",
    "    \n",
    "    for filename in findFiles('textFile/*.txt'):\n",
    "        words = readWords(filename)\n",
    "        logging.debug('words: {}'.format(words))\n",
    "        all_words = all_words + words\n",
    "    \n",
    "    logging.debug('all_words: {}'.format((all_words)))\n",
    "    \n",
    "    unique_sorted_all_words = sortedUniqueWords(all_words)\n",
    "    logging.debug('unique_sorted_all_words: {}'.format(unique_sorted_all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file: textFile\\test 1.txt\n",
      "words: ['his', 'is', 'a', 'test', 'test', 'test', 'test', 'test', 'test']\n",
      "file: textFile\\test 2.txt\n",
      "words: ['i', 'am', 'here', 'i', 'am', 'not', 'there', 'where', 'are', 'you', 'where', 'is', 'she']\n",
      "file: textFile\\test 3.txt\n",
      "words: ['this', 'is', 'a', 'dog', 'this', 'is', 'a', 'cat', 'dog', 'is', 'not', 'a', 'cat']\n",
      "\n",
      "words_in_a_document: {'test 1': ['his', 'is', 'a', 'test', 'test', 'test', 'test', 'test', 'test'], 'test 2': ['i', 'am', 'here', 'i', 'am', 'not', 'there', 'where', 'are', 'you', 'where', 'is', 'she'], 'test 3': ['this', 'is', 'a', 'dog', 'this', 'is', 'a', 'cat', 'dog', 'is', 'not', 'a', 'cat']}\n",
      "\n",
      "all_words: ['his', 'is', 'a', 'test', 'test', 'test', 'test', 'test', 'test', 'i', 'am', 'here', 'i', 'am', 'not', 'there', 'where', 'are', 'you', 'where', 'is', 'she', 'this', 'is', 'a', 'dog', 'this', 'is', 'a', 'cat', 'dog', 'is', 'not', 'a', 'cat']\n",
      "sorted_unique_all_words: ['a' 'am' 'are' 'cat' 'dog' 'here' 'his' 'i' 'is' 'not' 'she' 'test'\n",
      " 'there' 'this' 'where' 'you']\n",
      "\n",
      "all_word_count\n",
      "OrderedDict([('test 1', OrderedDict([('LENGTH', 9), ('a', 1), ('am', 0), ('are', 0), ('cat', 0), ('dog', 0), ('here', 0), ('his', 1), ('i', 0), ('is', 1), ('not', 0), ('she', 0), ('test', 6), ('there', 0), ('this', 0), ('where', 0), ('you', 0)])), ('test 2', OrderedDict([('LENGTH', 13), ('a', 0), ('am', 2), ('are', 1), ('cat', 0), ('dog', 0), ('here', 1), ('his', 0), ('i', 2), ('is', 1), ('not', 1), ('she', 1), ('test', 0), ('there', 1), ('this', 0), ('where', 2), ('you', 1)])), ('test 3', OrderedDict([('LENGTH', 13), ('a', 3), ('am', 0), ('are', 0), ('cat', 2), ('dog', 2), ('here', 0), ('his', 0), ('i', 0), ('is', 3), ('not', 1), ('she', 0), ('test', 0), ('there', 0), ('this', 2), ('where', 0), ('you', 0)]))])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# words_in_a_document: collects of words. each collect corresponding to its own document\n",
    "# sorted_unique_all_words: sorted bag of words\n",
    "# allWordCount: two dimension of order dictionary. dimension 0 corrsponding to document.\n",
    "#               dimension 1 corresponding to word count in the document with <key, value> = <word, word count> pairs.\n",
    "#               a special key 'LENGTH' record total word counts\n",
    "#\n",
    "\n",
    "all_words = []\n",
    "words_in_a_document = {}\n",
    "    \n",
    "for filename in findFiles('textFile/*.txt'):\n",
    "    words = readWords(filename)\n",
    "    logging.debug('file: {}'.format(filename))\n",
    "    logging.debug('words: {}'.format(words))\n",
    "    words_in_a_document[os.path.splitext(os.path.basename(filename))[0]] = words\n",
    "    all_words = all_words + words\n",
    "    \n",
    "logging.debug('\\nwords_in_a_document: {}'.format((words_in_a_document)))\n",
    "\n",
    "logging.debug('\\nall_words: {}'.format((all_words)))    \n",
    "sorted_unique_all_words = sortedUniqueWords(all_words)\n",
    "logging.debug('sorted_unique_all_words: {}'.format(sorted_unique_all_words))\n",
    "    \n",
    "all_word_count = OrderedDict()\n",
    "    \n",
    "for document in words_in_a_document:\n",
    "    words = words_in_a_document[document]\n",
    "    wordCount = OrderedDict()\n",
    "    wordCount['LENGTH'] = len(words)\n",
    "    for w in sorted_unique_all_words:\n",
    "        # logging.debug(\"{}: {} times\".format(w, words.count(w)))\n",
    "        wordCount[w] = words.count(w)\n",
    "    all_word_count[document] = wordCount\n",
    "\n",
    "logging.debug(\"\\nall_word_count\")\n",
    "logging.debug(all_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "number of bag of words: 16\n",
      "\n",
      "document test 1\n",
      "OrderedDict([('a', 0.1120976692563818), ('am', 0.0011098779134295228), ('are', 0.0011098779134295228), ('cat', 0.0011098779134295228), ('dog', 0.0011098779134295228), ('here', 0.0011098779134295228), ('his', 0.1120976692563818), ('i', 0.0011098779134295228), ('is', 0.1120976692563818), ('not', 0.0011098779134295228), ('she', 0.0011098779134295228), ('test', 0.6670366259711432), ('there', 0.0011098779134295228), ('this', 0.0011098779134295228), ('where', 0.0011098779134295228), ('you', 0.0011098779134295228)])\n",
      "\n",
      "document test 2\n",
      "OrderedDict([('a', 0.0007686395080707148), ('am', 0.15449654112221367), ('are', 0.0776325903151422), ('cat', 0.0007686395080707148), ('dog', 0.0007686395080707148), ('here', 0.0776325903151422), ('his', 0.0007686395080707148), ('i', 0.15449654112221367), ('is', 0.0776325903151422), ('not', 0.0776325903151422), ('she', 0.0776325903151422), ('test', 0.0007686395080707148), ('there', 0.0776325903151422), ('this', 0.0007686395080707148), ('where', 0.15449654112221367), ('you', 0.0776325903151422)])\n",
      "\n",
      "document test 3\n",
      "OrderedDict([('a', 0.23136049192928515), ('am', 0.0007686395080707148), ('are', 0.0007686395080707148), ('cat', 0.15449654112221367), ('dog', 0.15449654112221367), ('here', 0.0007686395080707148), ('his', 0.0007686395080707148), ('i', 0.0007686395080707148), ('is', 0.23136049192928515), ('not', 0.0776325903151422), ('she', 0.0007686395080707148), ('test', 0.0007686395080707148), ('there', 0.0007686395080707148), ('this', 0.15449654112221367), ('where', 0.0007686395080707148), ('you', 0.0007686395080707148)])\n",
      "\n",
      "words tf\n",
      "OrderedDict([('test 1', OrderedDict([('a', 0.1120976692563818), ('am', 0.0011098779134295228), ('are', 0.0011098779134295228), ('cat', 0.0011098779134295228), ('dog', 0.0011098779134295228), ('here', 0.0011098779134295228), ('his', 0.1120976692563818), ('i', 0.0011098779134295228), ('is', 0.1120976692563818), ('not', 0.0011098779134295228), ('she', 0.0011098779134295228), ('test', 0.6670366259711432), ('there', 0.0011098779134295228), ('this', 0.0011098779134295228), ('where', 0.0011098779134295228), ('you', 0.0011098779134295228)])), ('test 2', OrderedDict([('a', 0.0007686395080707148), ('am', 0.15449654112221367), ('are', 0.0776325903151422), ('cat', 0.0007686395080707148), ('dog', 0.0007686395080707148), ('here', 0.0776325903151422), ('his', 0.0007686395080707148), ('i', 0.15449654112221367), ('is', 0.0776325903151422), ('not', 0.0776325903151422), ('she', 0.0776325903151422), ('test', 0.0007686395080707148), ('there', 0.0776325903151422), ('this', 0.0007686395080707148), ('where', 0.15449654112221367), ('you', 0.0776325903151422)])), ('test 3', OrderedDict([('a', 0.23136049192928515), ('am', 0.0007686395080707148), ('are', 0.0007686395080707148), ('cat', 0.15449654112221367), ('dog', 0.15449654112221367), ('here', 0.0007686395080707148), ('his', 0.0007686395080707148), ('i', 0.0007686395080707148), ('is', 0.23136049192928515), ('not', 0.0776325903151422), ('she', 0.0007686395080707148), ('test', 0.0007686395080707148), ('there', 0.0007686395080707148), ('this', 0.15449654112221367), ('where', 0.0007686395080707148), ('you', 0.0007686395080707148)]))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# count words tf, words_tf\n",
    "#\n",
    "\n",
    "words_tf = OrderedDict()\n",
    "num_bow = len(sorted_unique_all_words)\n",
    "logging.debug(\"number of bag of words: {}\\n\".format(num_bow))\n",
    "\n",
    "for document in all_word_count:\n",
    "    tf = OrderedDict()\n",
    "    for word in all_word_count[document]:\n",
    "        if word != 'LENGTH':\n",
    "            tf[word] = (all_word_count[document][word] + 0.01) / (all_word_count[document]['LENGTH'] + 0.01)\n",
    "    logging.debug(\"document {}\".format(document))\n",
    "    logging.debug(\"{}\\n\".format(tf))\n",
    "    words_tf[document] = tf\n",
    "logging.debug(\"words tf\")\n",
    "logging.debug(\"{}\\n\".format(words_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "word a's document count = 2\n",
      "word am's document count = 1\n",
      "word are's document count = 1\n",
      "word cat's document count = 1\n",
      "word dog's document count = 1\n",
      "word here's document count = 1\n",
      "word his's document count = 1\n",
      "word i's document count = 1\n",
      "word is's document count = 3\n",
      "word not's document count = 2\n",
      "word she's document count = 1\n",
      "word test's document count = 1\n",
      "word there's document count = 1\n",
      "word this's document count = 1\n",
      "word where's document count = 1\n",
      "word you's document count = 1\n",
      "\n",
      "words idf\n",
      "OrderedDict([('a', 1.55), ('am', 3.1), ('are', 3.1), ('cat', 3.1), ('dog', 3.1), ('here', 3.1), ('his', 3.1), ('i', 3.1), ('is', 1.0333333333333334), ('not', 1.55), ('she', 3.1), ('test', 3.1), ('there', 3.1), ('this', 3.1), ('where', 3.1), ('you', 3.1)])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# count words idf, words_idf\n",
    "#\n",
    "\n",
    "words_idf = OrderedDict()\n",
    "documents = len(all_word_count) + 0.1\n",
    "\n",
    "for word in sorted_unique_all_words:\n",
    "    doc_count = 0\n",
    "    for document in all_word_count:\n",
    "        if all_word_count[document][word] != 0:\n",
    "            doc_count = doc_count + 1\n",
    "    logging.debug(\"word {}\\'s document count = {}\".format(word, doc_count))\n",
    "    words_idf[word] = documents / doc_count\n",
    "logging.debug(\"\\nwords idf\")\n",
    "logging.debug(words_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "word: a         , tf: 0.112098, idf: 1.550000, log(tf): -2.188385, log(idf): 0.438255, (1+logtf)*logidf: -0.520815\n",
      "word: am        , tf: 0.001110, idf: 3.100000, log(tf): -6.803505, log(idf): 1.131402, (1+logtf)*logidf: -6.566098\n",
      "word: are       , tf: 0.001110, idf: 3.100000, log(tf): -6.803505, log(idf): 1.131402, (1+logtf)*logidf: -6.566098\n",
      "word: cat       , tf: 0.001110, idf: 3.100000, log(tf): -6.803505, log(idf): 1.131402, (1+logtf)*logidf: -6.566098\n",
      "word: dog       , tf: 0.001110, idf: 3.100000, log(tf): -6.803505, log(idf): 1.131402, (1+logtf)*logidf: -6.566098\n",
      "word: here      , tf: 0.001110, idf: 3.100000, log(tf): -6.803505, log(idf): 1.131402, (1+logtf)*logidf: -6.566098\n",
      "word: his       , tf: 0.112098, idf: 3.100000, log(tf): -2.188385, log(idf): 1.131402, (1+logtf)*logidf: -1.344541\n",
      "word: i         , tf: 0.001110, idf: 3.100000, log(tf): -6.803505, log(idf): 1.131402, (1+logtf)*logidf: -6.566098\n",
      "word: is        , tf: 0.112098, idf: 1.033333, log(tf): -2.188385, log(idf): 0.032790, (1+logtf)*logidf: -0.038967\n",
      "word: not       , tf: 0.001110, idf: 1.550000, log(tf): -6.803505, log(idf): 0.438255, (1+logtf)*logidf: -2.543415\n",
      "word: she       , tf: 0.001110, idf: 3.100000, log(tf): -6.803505, log(idf): 1.131402, (1+logtf)*logidf: -6.566098\n",
      "word: test      , tf: 0.667037, idf: 3.100000, log(tf): -0.404910, log(idf): 1.131402, (1+logtf)*logidf: 0.673286\n",
      "word: there     , tf: 0.001110, idf: 3.100000, log(tf): -6.803505, log(idf): 1.131402, (1+logtf)*logidf: -6.566098\n",
      "word: this      , tf: 0.001110, idf: 3.100000, log(tf): -6.803505, log(idf): 1.131402, (1+logtf)*logidf: -6.566098\n",
      "word: where     , tf: 0.001110, idf: 3.100000, log(tf): -6.803505, log(idf): 1.131402, (1+logtf)*logidf: -6.566098\n",
      "word: you       , tf: 0.001110, idf: 3.100000, log(tf): -6.803505, log(idf): 1.131402, (1+logtf)*logidf: -6.566098\n",
      "document test 1\n",
      "OrderedDict([('a', -0.5208154724845149), ('am', -6.566098102507777), ('are', -6.566098102507777), ('cat', -6.566098102507777), ('dog', -6.566098102507777), ('here', -6.566098102507777), ('his', -1.3445410049676767), ('i', -6.566098102507777), ('is', -0.03896692509529855), ('not', -2.5434147958317386), ('she', -6.566098102507777), ('test', 0.6732857170016172), ('there', -6.566098102507777), ('this', -6.566098102507777), ('where', -6.566098102507777), ('you', -6.566098102507777)])\n",
      "\n",
      "word: a         , tf: 0.000769, idf: 1.550000, log(tf): -7.170888, log(idf): 0.438255, (1+logtf)*logidf: -2.704422\n",
      "word: am        , tf: 0.154497, idf: 3.100000, log(tf): -1.867584, log(idf): 1.131402, (1+logtf)*logidf: -0.981586\n",
      "word: are       , tf: 0.077633, idf: 3.100000, log(tf): -2.555768, log(idf): 1.131402, (1+logtf)*logidf: -1.760199\n",
      "word: cat       , tf: 0.000769, idf: 3.100000, log(tf): -7.170888, log(idf): 1.131402, (1+logtf)*logidf: -6.981756\n",
      "word: dog       , tf: 0.000769, idf: 3.100000, log(tf): -7.170888, log(idf): 1.131402, (1+logtf)*logidf: -6.981756\n",
      "word: here      , tf: 0.077633, idf: 3.100000, log(tf): -2.555768, log(idf): 1.131402, (1+logtf)*logidf: -1.760199\n",
      "word: his       , tf: 0.000769, idf: 3.100000, log(tf): -7.170888, log(idf): 1.131402, (1+logtf)*logidf: -6.981756\n",
      "word: i         , tf: 0.154497, idf: 3.100000, log(tf): -1.867584, log(idf): 1.131402, (1+logtf)*logidf: -0.981586\n",
      "word: is        , tf: 0.077633, idf: 1.033333, log(tf): -2.555768, log(idf): 0.032790, (1+logtf)*logidf: -0.051013\n",
      "word: not       , tf: 0.077633, idf: 1.550000, log(tf): -2.555768, log(idf): 0.438255, (1+logtf)*logidf: -0.681823\n",
      "word: she       , tf: 0.077633, idf: 3.100000, log(tf): -2.555768, log(idf): 1.131402, (1+logtf)*logidf: -1.760199\n",
      "word: test      , tf: 0.000769, idf: 3.100000, log(tf): -7.170888, log(idf): 1.131402, (1+logtf)*logidf: -6.981756\n",
      "word: there     , tf: 0.077633, idf: 3.100000, log(tf): -2.555768, log(idf): 1.131402, (1+logtf)*logidf: -1.760199\n",
      "word: this      , tf: 0.000769, idf: 3.100000, log(tf): -7.170888, log(idf): 1.131402, (1+logtf)*logidf: -6.981756\n",
      "word: where     , tf: 0.154497, idf: 3.100000, log(tf): -1.867584, log(idf): 1.131402, (1+logtf)*logidf: -0.981586\n",
      "word: you       , tf: 0.077633, idf: 3.100000, log(tf): -2.555768, log(idf): 1.131402, (1+logtf)*logidf: -1.760199\n",
      "document test 2\n",
      "OrderedDict([('a', -2.70442230393436), ('am', -0.9815858835059983), ('are', -1.760199156825053), ('cat', -6.981756254365153), ('dog', -6.981756254365153), ('here', -1.760199156825053), ('his', -6.981756254365153), ('i', -0.9815858835059983), ('is', -0.05101335581688595), ('not', -0.6818229805871361), ('she', -1.760199156825053), ('test', -6.981756254365153), ('there', -1.760199156825053), ('this', -6.981756254365153), ('where', -0.9815858835059983), ('you', -1.760199156825053)])\n",
      "\n",
      "word: a         , tf: 0.231360, idf: 1.550000, log(tf): -1.463778, log(idf): 0.438255, (1+logtf)*logidf: -0.203253\n",
      "word: am        , tf: 0.000769, idf: 3.100000, log(tf): -7.170888, log(idf): 1.131402, (1+logtf)*logidf: -6.981756\n",
      "word: are       , tf: 0.000769, idf: 3.100000, log(tf): -7.170888, log(idf): 1.131402, (1+logtf)*logidf: -6.981756\n",
      "word: cat       , tf: 0.154497, idf: 3.100000, log(tf): -1.867584, log(idf): 1.131402, (1+logtf)*logidf: -0.981586\n",
      "word: dog       , tf: 0.154497, idf: 3.100000, log(tf): -1.867584, log(idf): 1.131402, (1+logtf)*logidf: -0.981586\n",
      "word: here      , tf: 0.000769, idf: 3.100000, log(tf): -7.170888, log(idf): 1.131402, (1+logtf)*logidf: -6.981756\n",
      "word: his       , tf: 0.000769, idf: 3.100000, log(tf): -7.170888, log(idf): 1.131402, (1+logtf)*logidf: -6.981756\n",
      "word: i         , tf: 0.000769, idf: 3.100000, log(tf): -7.170888, log(idf): 1.131402, (1+logtf)*logidf: -6.981756\n",
      "word: is        , tf: 0.231360, idf: 1.033333, log(tf): -1.463778, log(idf): 0.032790, (1+logtf)*logidf: -0.015207\n",
      "word: not       , tf: 0.077633, idf: 1.550000, log(tf): -2.555768, log(idf): 0.438255, (1+logtf)*logidf: -0.681823\n",
      "word: she       , tf: 0.000769, idf: 3.100000, log(tf): -7.170888, log(idf): 1.131402, (1+logtf)*logidf: -6.981756\n",
      "word: test      , tf: 0.000769, idf: 3.100000, log(tf): -7.170888, log(idf): 1.131402, (1+logtf)*logidf: -6.981756\n",
      "word: there     , tf: 0.000769, idf: 3.100000, log(tf): -7.170888, log(idf): 1.131402, (1+logtf)*logidf: -6.981756\n",
      "word: this      , tf: 0.154497, idf: 3.100000, log(tf): -1.867584, log(idf): 1.131402, (1+logtf)*logidf: -0.981586\n",
      "word: where     , tf: 0.000769, idf: 3.100000, log(tf): -7.170888, log(idf): 1.131402, (1+logtf)*logidf: -6.981756\n",
      "word: you       , tf: 0.000769, idf: 3.100000, log(tf): -7.170888, log(idf): 1.131402, (1+logtf)*logidf: -6.981756\n",
      "document test 3\n",
      "OrderedDict([('a', -0.2032530890403541), ('am', -6.981756254365153), ('are', -6.981756254365153), ('cat', -0.9815858835059983), ('dog', -0.9815858835059983), ('here', -6.981756254365153), ('his', -6.981756254365153), ('i', -6.981756254365153), ('is', -0.01520720545847265), ('not', -0.6818229805871361), ('she', -6.981756254365153), ('test', -6.981756254365153), ('there', -6.981756254365153), ('this', -0.9815858835059983), ('where', -6.981756254365153), ('you', -6.981756254365153)])\n",
      "\n",
      "words tfidf\n",
      "OrderedDict([('test 1', OrderedDict([('a', -0.5208154724845149), ('am', -6.566098102507777), ('are', -6.566098102507777), ('cat', -6.566098102507777), ('dog', -6.566098102507777), ('here', -6.566098102507777), ('his', -1.3445410049676767), ('i', -6.566098102507777), ('is', -0.03896692509529855), ('not', -2.5434147958317386), ('she', -6.566098102507777), ('test', 0.6732857170016172), ('there', -6.566098102507777), ('this', -6.566098102507777), ('where', -6.566098102507777), ('you', -6.566098102507777)])), ('test 2', OrderedDict([('a', -2.70442230393436), ('am', -0.9815858835059983), ('are', -1.760199156825053), ('cat', -6.981756254365153), ('dog', -6.981756254365153), ('here', -1.760199156825053), ('his', -6.981756254365153), ('i', -0.9815858835059983), ('is', -0.05101335581688595), ('not', -0.6818229805871361), ('she', -1.760199156825053), ('test', -6.981756254365153), ('there', -1.760199156825053), ('this', -6.981756254365153), ('where', -0.9815858835059983), ('you', -1.760199156825053)])), ('test 3', OrderedDict([('a', -0.2032530890403541), ('am', -6.981756254365153), ('are', -6.981756254365153), ('cat', -0.9815858835059983), ('dog', -0.9815858835059983), ('here', -6.981756254365153), ('his', -6.981756254365153), ('i', -6.981756254365153), ('is', -0.01520720545847265), ('not', -0.6818229805871361), ('she', -6.981756254365153), ('test', -6.981756254365153), ('there', -6.981756254365153), ('this', -0.9815858835059983), ('where', -6.981756254365153), ('you', -6.981756254365153)]))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# count words tfidf, words_tfidf in python dictionary implementation\n",
    "# also tfidf_array in python numpy array implementation\n",
    "#\n",
    "\n",
    "words_tfidf = OrderedDict()\n",
    "\n",
    "for document in all_word_count:\n",
    "    tfidf = OrderedDict()\n",
    "    for word in all_word_count[document]:\n",
    "        if word != 'LENGTH':\n",
    "            logging.debug(\"word: {:10s}, tf: {:.6f}, idf: {:.6f}, log(tf): {:.6f}, log(idf): {:.6f}, (1+logtf)*logidf: {:.6f}\".format(\n",
    "               word, words_tf[document][word], words_idf[word],\n",
    "               math.log(words_tf[document][word]), math.log(words_idf[word]),\n",
    "               (1 + math.log(words_tf[document][word])) * math.log(words_idf[word])))\n",
    "            tfidf[word] = (1 + math.log(words_tf[document][word])) * math.log(words_idf[word])\n",
    "            \n",
    "    logging.debug(\"document {}\".format(document))\n",
    "    logging.debug(\"{}\\n\".format(tfidf))\n",
    "    words_tfidf[document] = tfidf\n",
    "    \n",
    "logging.debug(\"words tfidf\")\n",
    "logging.debug(\"{}\\n\".format(words_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    test 1              test 2              test 3              \n",
      "a                -0.5208154725       -2.7044223039       -0.2032530890\n",
      "am               -6.5660981025       -0.9815858835       -6.9817562544\n",
      "are              -6.5660981025       -1.7601991568       -6.9817562544\n",
      "cat              -6.5660981025       -6.9817562544       -0.9815858835\n",
      "dog              -6.5660981025       -6.9817562544       -0.9815858835\n",
      "here             -6.5660981025       -1.7601991568       -6.9817562544\n",
      "his              -1.3445410050       -6.9817562544       -6.9817562544\n",
      "i                -6.5660981025       -0.9815858835       -6.9817562544\n",
      "is               -0.0389669251       -0.0510133558       -0.0152072055\n",
      "not              -2.5434147958       -0.6818229806       -0.6818229806\n",
      "she              -6.5660981025       -1.7601991568       -6.9817562544\n",
      "test              0.6732857170       -6.9817562544       -6.9817562544\n",
      "there            -6.5660981025       -1.7601991568       -6.9817562544\n",
      "this             -6.5660981025       -6.9817562544       -0.9815858835\n",
      "where            -6.5660981025       -0.9815858835       -6.9817562544\n",
      "you              -6.5660981025       -1.7601991568       -6.9817562544\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# print out word's tf.idf\n",
    "#\n",
    "\n",
    "print(\"{:20s}\".format(\"\"), end='')\n",
    "for document in words_tfidf:\n",
    "    print(\"{:20s}\".format(document), end='')\n",
    "print(\"\")\n",
    "for word in sorted_unique_all_words:\n",
    "    print(\"{:10s}\".format(word), end='')\n",
    "    for document in words_tfidf:\n",
    "        print(\"{:20.10f}\".format(words_tfidf[document][word]), end='')\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test 1\n",
      "[('test', 0.6732857170016172), ('is', -0.03896692509529855), ('a', -0.5208154724845149)]\n",
      "test 2\n",
      "[('is', -0.05101335581688595), ('not', -0.6818229805871361), ('am', -0.9815858835059983)]\n",
      "test 3\n",
      "[('is', -0.01520720545847265), ('a', -0.2032530890403541), ('not', -0.6818229805871361)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "\n",
    "for document in words_tfidf:\n",
    "    k = Counter(words_tfidf[document]) \n",
    "    logging.debug(document)\n",
    "    logging.debug(k.most_common(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
